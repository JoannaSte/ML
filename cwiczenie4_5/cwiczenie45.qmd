---
title: "Projekt ML"
subtitle: "Cwiczenie 3"
date: today
author: "Joanna Stępień"
format: 
  html:
    
    toc: true
    toc-depth: 3
    toc-location: left
    toc-title: "Spis Treści"
    number-sections: true
    number-depth: 3
    code-fold: show
    code-summary: "Napis"
    code-tools: true
    code-block-bg: "grey50"
    code-block-border-left: "black"
    code-line-numbers: true
    code-copy: true
    html-math-method: katex
    embed-resources: true
    smooth-scroll: true
    anchor-sections: true
    citation: true
    theme: 
      light: cosmo
      dark: darkly
    fontsize: 1.0em
    linestretch: 1.5
execute: 
  
  eval: true
  warning: false
  echo: true
  error: false
  cache: true
editor_options: 
  chunk_output_type: console
---
---

## Ładujemy niezbędne pakiety
```{r}
library(tidymodels) 
library(skimr) 
library(GGally) 
library(openair) 
tidymodels_prefer()
```

## ładujemy zbiór danych,wybieramy konkretny rok, robimy analize wartości oraz usuwamy braki w danych

```{r}
air <- mydata |> selectByDate(year = 2002) 
air |> skim()
air
air <- air |> na.omit()
air
```

## Sprawdzamy korelacje pomiędzy nox i no2 i rysujemy dla nich wykres regresji liniowe. Wyszło nam że dane są mozno skorelowane

```{r}
set.seed(222)
air[sample(1:nrow(air), size = 300, replace = F),] |> 
  select(nox, no2) |> 
  ggpairs()

library(ggpubr)
# wykres regresji liniowej, do sprawdzenia danych 
set.seed(222)
air[sample(1:nrow(air), size = 300, replace = F),] |> 
  select(nox, no2) |> 
  ggplot(aes(nox, no2)) +
  geom_point() +
  geom_smooth(method = "lm", se = T, formula = y ~ x) + 
  stat_cor(label.x = 10, label.y = 80) + 
  stat_regline_equation(label.x = 10, label.y = 82) +
  theme_bw()
```

## Badamy rozkład wartości stężeń azotu 

```{r}
air |>    
  ggplot(aes(date, o3)) +     
  geom_line() +     
  theme_bw()
```

## Badamy zakres stężeń, labelujemy je w zależności czy są niskie i wysokie według przyjętej wartości 10 i liczymy ile jest stężeń niskich i wysokich

```{r}
air |> 
  pull(o3) |> 
  range()  

air <-
  air |>
  mutate(ozone = cut(
    o3,
    breaks = c(-0.1, 10, 53),
    labels = c("Niskie", "Wysokie")
  ))
air |> count(ozone)
```
## Dzielimy dataset na zbiór testowy i treningowy
```{r}
set.seed(222)
data_split <- initial_split(data = air, prop = 3/4)
train_data <- training(data_split)
test_data <-  testing(data_split)
```
## Tworzymy recepture, nie używamy daty bo jest problematyczną wartości i nox bo jest silnie skorelowane z inną zmienną w zbiorze
```{r}
air_recipe <- recipe(ozone ~ ., data = train_data) |> 
  update_role(date, nox, new_role="nowe_inf") 
```

## Sprwadzmy jakie parametry możemy jeszcze dostrajać w algorytmie drzew dezyzyjnych i zauważamy jeszcze parametr min_n
```{r}
args(decision_tree)
?decision_tree()

```

## Tworzymy specyfikacje modelu określając jakie parametry chcemy dostrajać i dodajemy jeszcze parametr min_n. Do tego towrzymy przepływ pracy oraz siatkę która nam zwróci przez 3 parametry 5*5*5 różnych kombinacji
```{r}
decision_tree <- decision_tree(
  cost_complexity = tune(),
  tree_depth = tune(),
  min_n = tune()
) |>
  set_engine("rpart") |>
  set_mode("classification")

# Utworzenie workflow
tree_work <- workflow() |>
  add_model(decision_tree) |>
  add_recipe(air_recipe)
# Stworzenie siatki parametrów
siatka <- grid_regular(
  cost_complexity(),
  tree_depth(),
  min_n(),
  levels = 5
)

```

## dzielimy zestaw danych na foldy, wybieramy jakie metryki chcemy sledzić dostarjamy model za pomoca parametrów i metryk które wybraliśmy
```{r}

set.seed(234)
folds <- vfold_cv(train_data, v = 5)


metrics <- metric_set(
  accuracy,
  roc_auc,
  precision,
  recall
)


tree_tuning <- tune_grid(
  tree_work,
  resamples = folds,
  grid = siatka,
  metrics = metrics
)

```

## Wybiramy najlepsyz model za pomocą accuracy i 
```{r}

best_model <- select_best(tree_tuning, metric ="accuracy")
# Wyświetlenie najlepszych wyników
print("Najlepsze wyniki dla drzewa decyzyjnego:")
show_best(tree_tuning,  metric ="accuracy")

```

## Uczymy model z najbardzije korzystnymi wartościami parametrów u obserwujemy krzywą ROC. NAjlepsze accuracy osiągnęło wartość 0.855, co jest wyższe od osiągniętej wartości w przypadku dostrajania tylko 2 parametrów drzewa decyzyjnego 
```{r}
final_mod <-  
  work |> 
  finalize_workflow(best_model)

final_fit <- 
  final_mod |> 
  last_fit(split = split)

final_fit %>%
  collect_metrics()

final_fit |> 
  collect_predictions() |> 
  roc_curve(truth = class, .pred_PS) |> 
  autoplot()

final_fit |> extract_workflow()


final_fit |> 
  extract_workflow() |> 
  extract_fit_parsnip() |>
  vip() 

```

## Powtarzamy poprzednie kroki ale tym razem dla alorytmy lasu losowego. Dostrajamy 3 parametry: mtry, trees i min_n
```{r}
rand_forest <- 
  rand_forest(mtry = tune(),
              min_n = tune(),
              trees = tune()) |>
  set_engine(engine = "ranger") |> 
  set_mode("classification")

# Utworzenie workflow
tree_work <- workflow() |>
  add_model(rand_forest) |>
  add_recipe(air_recipe)
# Stworzenie siatki parametrów
siatka <- grid_regular(
  mtry(range=c(1,5)),
  trees(),
  min_n(),
  levels = 5
)
siatka
# Przygotowanie foldów CV
set.seed(234)
folds <- vfold_cv(train_data, v = 5)

# Zdefiniowanie metryk oceny
metrics <- metric_set(
  accuracy,
  roc_auc,
  precision,
  recall
)

# Dostrajanie modelu
tree_tuning <- tune_grid(
  tree_work,
  resamples = folds,
  grid = siatka,
  metrics = metrics
)

best_model <- select_best(tree_tuning, metric ="accuracy")
# Wyświetlenie najlepszych wyników
print("Najlepsze wyniki dla drzewa decyzyjnego:")
show_best(tree_tuning,  metric ="accuracy")


final_mod <-  
  work |> 
  finalize_workflow(best_model)

final_fit <- 
  final_mod |> 
  last_fit(split = split)

final_fit %>%
  collect_metrics()

final_fit |> 
  collect_predictions() |> 
  roc_curve(truth = class, .pred_PS) |> 
  autoplot()

final_fit |> extract_workflow()


final_fit |> 
  extract_workflow() |> 
  extract_fit_parsnip() |>
  vip() 

```

